#!/usr/bin/env python3
"""
Go项目复杂度分析工具 - 更智能的项目复杂度评估
排除第三方代码，使用认知复杂度、圈复杂度等更好的指标
"""

import os
import re
import ast
import pathlib
from collections import defaultdict, Counter
from dataclasses import dataclass
from typing import List, Dict, Set, Tuple, Optional


@dataclass
class FunctionInfo:
    name: str
    line_start: int
    line_end: int
    cyclomatic_complexity: int
    cognitive_complexity: int
    nesting_depth: int
    parameters: int
    return_values: int


@dataclass
class FileComplexity:
    path: str
    total_lines: int
    code_lines: int
    comment_lines: int
    empty_lines: int
    functions: List[FunctionInfo]
    structs_count: int
    interfaces_count: int
    imports_count: int
    max_nesting_depth: int
    avg_function_length: float
    is_test: bool
    is_generated: bool
    is_third_party: bool


class GoComplexityAnalyzer:
    def __init__(self, root_dir='.'):
        self.root_dir = root_dir
        self.third_party_patterns = [
            'vendor/',
            '.git/',
            'node_modules/',
            # 常见的自动生成文件模式
            r'.*\.pb\.go$',
            r'.*_generated\.go$',
            r'mock_.*\.go$',
        ]
        
        # 排除不重要的目录
        self.exclude_dirs = {
            '.git', 'vendor', 'node_modules', '.vscode', 
            '.idea', 'tmp', 'temp', 'build', 'dist'
        }

    def is_third_party_or_generated(self, file_path: str) -> tuple[bool, bool]:
        """检查文件是否是第三方代码或自动生成的代码"""
        rel_path = os.path.relpath(file_path, self.root_dir)
        
        # 检查是否在排除目录中
        path_parts = rel_path.split(os.sep)
        for part in path_parts:
            if part in self.exclude_dirs:
                return True, False
        
        # 检查是否匹配第三方模式
        for pattern in self.third_party_patterns:
            if pattern.endswith('/'):
                if rel_path.startswith(pattern):
                    return True, False
            elif re.match(pattern, rel_path):
                return True, False
        
        # 检查文件内容是否包含生成标记
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                first_lines = f.read(500)  # 只读前500字符
                if any(marker in first_lines for marker in [
                    'Code generated',
                    'DO NOT EDIT',
                    'AUTO-GENERATED',
                    'This file was autogenerated'
                ]):
                    return False, True
        except:
            pass
        
        return False, False

    def calculate_cyclomatic_complexity(self, content: str) -> int:
        """计算圈复杂度"""
        # 基础复杂度为1
        complexity = 1
        
        # 增加复杂度的Go语言结构
        complexity_patterns = [
            r'\bif\b',
            r'\belse\s+if\b',
            r'\bfor\b',
            r'\bswitch\b',
            r'\bcase\b',
            r'\bselect\b',
            r'\bgo\b\s+\w+\s*\(',  # goroutine
            r'\bdefer\b',
            r'&&',
            r'\|\|',
            r'\?.*:',  # 三元操作符
        ]
        
        for pattern in complexity_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            complexity += len(matches)
        
        return complexity

    def calculate_cognitive_complexity(self, content: str) -> int:
        """计算认知复杂度（更接近人类理解代码的难度）"""
        cognitive = 0
        nesting_level = 0
        
        lines = content.split('\n')
        
        for line in lines:
            stripped = line.strip()
            
            # 计算嵌套级别
            if any(keyword in stripped for keyword in ['if', 'for', 'switch', 'select']):
                cognitive += 1 + nesting_level  # 基础复杂度 + 嵌套惩罚
                if '{' in stripped:
                    nesting_level += 1
            elif stripped.startswith('case ') or stripped.startswith('default:'):
                cognitive += 1
            elif '&&' in stripped or '||' in stripped:
                cognitive += 1
            elif stripped.startswith('go '):  # goroutine
                cognitive += 1
            elif stripped.startswith('defer '):
                cognitive += 1
            
            # 检查块结束
            if '}' in stripped:
                nesting_level = max(0, nesting_level - 1)
        
        return cognitive

    def calculate_nesting_depth(self, content: str) -> int:
        """计算最大嵌套深度"""
        max_depth = 0
        current_depth = 0
        
        for char in content:
            if char == '{':
                current_depth += 1
                max_depth = max(max_depth, current_depth)
            elif char == '}':
                current_depth = max(0, current_depth - 1)
        
        return max_depth

    def extract_function_info(self, content: str) -> List[FunctionInfo]:
        """提取函数信息"""
        functions = []
        lines = content.split('\n')
        
        # 简单的Go函数匹配
        func_pattern = r'func\s+(?:\([^)]*\)\s+)?(\w+)\s*\(([^)]*)\)\s*(?:\([^)]*\))?\s*(?:\w+\s*)?{'
        
        for i, line in enumerate(lines):
            match = re.search(func_pattern, line)
            if match:
                func_name = match.group(1)
                params = match.group(2) if match.group(2) else ""
                
                # 计算参数数量
                param_count = len([p.strip() for p in params.split(',') if p.strip()]) if params.strip() else 0
                
                # 找到函数结束位置（简化版本）
                brace_count = 0
                func_start = i + 1
                func_end = func_start
                started = False
                
                for j in range(i, len(lines)):
                    for char in lines[j]:
                        if char == '{':
                            brace_count += 1
                            started = True
                        elif char == '}':
                            brace_count -= 1
                            
                        if started and brace_count == 0:
                            func_end = j + 1
                            break
                    if started and brace_count == 0:
                        break
                
                # 提取函数内容
                func_content = '\n'.join(lines[i:func_end])
                
                functions.append(FunctionInfo(
                    name=func_name,
                    line_start=func_start,
                    line_end=func_end,
                    cyclomatic_complexity=self.calculate_cyclomatic_complexity(func_content),
                    cognitive_complexity=self.calculate_cognitive_complexity(func_content),
                    nesting_depth=self.calculate_nesting_depth(func_content),
                    parameters=param_count,
                    return_values=0  # 简化，不解析返回值
                ))
        
        return functions

    def analyze_file(self, file_path: str) -> FileComplexity:
        """分析单个Go文件"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except Exception as e:
            print(f"警告: 无法读取文件 {file_path}: {e}")
            return None

        # 基础统计
        total_lines = len(lines)
        empty_lines = sum(1 for line in lines if line.strip() == '')
        comment_lines = sum(1 for line in lines if line.strip().startswith('//'))
        code_lines = total_lines - empty_lines - comment_lines

        # 检查是否是第三方或生成的代码
        is_third_party, is_generated = self.is_third_party_or_generated(file_path)
        
        # 提取函数信息
        functions = self.extract_function_info(content)
        
        # 统计结构体和接口
        structs_count = len(re.findall(r'type\s+\w+\s+struct\s*{', content))
        interfaces_count = len(re.findall(r'type\s+\w+\s+interface\s*{', content))
        
        # 统计导入
        import_section = re.search(r'import\s*\((.*?)\)', content, re.DOTALL)
        if import_section:
            imports = [line.strip() for line in import_section.group(1).split('\n') if line.strip() and not line.strip().startswith('//')]
            imports_count = len([imp for imp in imports if imp])
        else:
            # 单行导入
            imports_count = len(re.findall(r'import\s+"[^"]+"', content))

        # 计算平均函数长度
        if functions:
            avg_function_length = sum(f.line_end - f.line_start for f in functions) / len(functions)
        else:
            avg_function_length = 0

        return FileComplexity(
            path=file_path,
            total_lines=total_lines,
            code_lines=code_lines,
            comment_lines=comment_lines,
            empty_lines=empty_lines,
            functions=functions,
            structs_count=structs_count,
            interfaces_count=interfaces_count,
            imports_count=imports_count,
            max_nesting_depth=self.calculate_nesting_depth(content),
            avg_function_length=avg_function_length,
            is_test=file_path.endswith('_test.go'),
            is_generated=is_generated,
            is_third_party=is_third_party
        )

    def categorize_files(self, files: List[FileComplexity]) -> Dict[str, List[FileComplexity]]:
        """将文件分类"""
        categories = {
            '核心业务逻辑': [],
            '测试代码': [],
            '工具和CLI': [],
            'API定义': [],
            '配置和初始化': [],
            '第三方/生成代码': []
        }
        
        for file in files:
            if file.is_third_party or file.is_generated:
                categories['第三方/生成代码'].append(file)
            elif file.is_test:
                categories['测试代码'].append(file)
            elif '/cmd/' in file.path:
                categories['工具和CLI'].append(file)
            elif '/api/' in file.path or 'types.go' in file.path:
                categories['API定义'].append(file)
            elif 'config' in file.path.lower() or 'init' in file.path.lower():
                categories['配置和初始化'].append(file)
            else:
                categories['核心业务逻辑'].append(file)
        
        return categories

    def analyze_project(self) -> Dict:
        """分析整个项目"""
        print("🔍 正在扫描Go文件...")
        
        go_files = []
        for root, dirs, files in os.walk(self.root_dir):
            # 过滤目录
            dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
            
            for file in files:
                if file.endswith('.go'):
                    file_path = os.path.join(root, file)
                    complexity = self.analyze_file(file_path)
                    if complexity:
                        go_files.append(complexity)

        print(f"📁 找到 {len(go_files)} 个Go文件")
        
        # 分类文件
        categorized = self.categorize_files(go_files)
        
        # 计算统计数据
        stats = {}
        for category, files in categorized.items():
            if not files:
                continue
                
            total_code_lines = sum(f.code_lines for f in files)
            total_functions = sum(len(f.functions) for f in files)
            total_complexity = sum(sum(func.cognitive_complexity for func in f.functions) for f in files)
            
            # 找出最复杂的函数
            all_functions = []
            for f in files:
                for func in f.functions:
                    all_functions.append((func, f.path))
            
            most_complex = sorted(all_functions, key=lambda x: x[0].cognitive_complexity, reverse=True)[:5]
            
            stats[category] = {
                'files_count': len(files),
                'total_code_lines': total_code_lines,
                'total_functions': total_functions,
                'total_complexity': total_complexity,
                'avg_complexity_per_function': total_complexity / max(total_functions, 1),
                'most_complex_functions': most_complex,
                'files': files
            }
        
        return stats

    def print_analysis(self, stats: Dict):
        """打印分析结果"""
        print("\n" + "="*80)
        print("🧠 GO项目复杂度分析报告")
        print("="*80)
        
        # 总览
        total_core_lines = sum(s['total_code_lines'] for k, s in stats.items() 
                              if k not in ['测试代码', '第三方/生成代码'])
        total_core_functions = sum(s['total_functions'] for k, s in stats.items() 
                                  if k not in ['测试代码', '第三方/生成代码'])
        total_core_complexity = sum(s['total_complexity'] for k, s in stats.items() 
                                   if k not in ['测试代码', '第三方/生成代码'])
        
        print(f"\n📊 核心代码概览 (排除测试和第三方代码):")
        print(f"  • 代码行数: {total_core_lines:,}")
        print(f"  • 函数数量: {total_core_functions:,}")
        print(f"  • 总认知复杂度: {total_core_complexity:,}")
        print(f"  • 平均函数复杂度: {total_core_complexity/max(total_core_functions,1):.1f}")
        
        # 复杂度等级评估
        if total_core_complexity / max(total_core_functions, 1) <= 5:
            complexity_level = "🟢 低复杂度 - 易于理解"
        elif total_core_complexity / max(total_core_functions, 1) <= 10:
            complexity_level = "🟡 中等复杂度 - 需要一定经验"
        elif total_core_complexity / max(total_core_functions, 1) <= 20:
            complexity_level = "🟠 高复杂度 - 需要深度理解"
        else:
            complexity_level = "🔴 极高复杂度 - 建议重构"
        
        print(f"\n🎯 项目复杂度等级: {complexity_level}")
        
        # 按类别详细分析
        print(f"\n📂 按模块分类分析:")
        print("-" * 70)
        
        for category, data in stats.items():
            if data['files_count'] == 0:
                continue
                
            print(f"\n🔸 {category}")
            print(f"   文件数: {data['files_count']}")
            print(f"   代码行: {data['total_code_lines']:,}")
            print(f"   函数数: {data['total_functions']}")
            print(f"   平均复杂度: {data['avg_complexity_per_function']:.1f}")
            
            # 显示最复杂的函数
            if data['most_complex_functions']:
                print(f"   最复杂函数:")
                for i, (func, path) in enumerate(data['most_complex_functions'][:3]):
                    rel_path = os.path.relpath(path, self.root_dir)
                    print(f"     {i+1}. {func.name} (复杂度:{func.cognitive_complexity}) - {rel_path}")
        
        # 重点关注区域建议
        print(f"\n💡 建议优先关注的学习路径:")
        print("-" * 50)
        
        # 找出核心API定义
        if 'API定义' in stats and stats['API定义']['files']:
            print("1️⃣ 先从API定义开始:")
            for file in sorted(stats['API定义']['files'], key=lambda f: f.structs_count + f.interfaces_count, reverse=True)[:3]:
                rel_path = os.path.relpath(file.path, self.root_dir)
                print(f"   📋 {rel_path} ({file.structs_count}个结构体, {file.interfaces_count}个接口)")
        
        # 核心业务逻辑中最简单的模块
        if '核心业务逻辑' in stats and stats['核心业务逻辑']['files']:
            simple_files = sorted(stats['核心业务逻辑']['files'], 
                                key=lambda f: sum(func.cognitive_complexity for func in f.functions))[:5]
            print("\n2️⃣ 然后学习简单的核心模块:")
            for file in simple_files:
                rel_path = os.path.relpath(file.path, self.root_dir)
                total_complexity = sum(func.cognitive_complexity for func in file.functions)
                print(f"   🧩 {rel_path} (复杂度:{total_complexity}, {len(file.functions)}个函数)")
        
        # 最需要重构的代码
        all_complex_functions = []
        for category, data in stats.items():
            if category not in ['测试代码', '第三方/生成代码']:
                all_complex_functions.extend(data['most_complex_functions'])
        
        if all_complex_functions:
            most_complex_overall = sorted(all_complex_functions, key=lambda x: x[0].cognitive_complexity, reverse=True)[:5]
            print(f"\n⚠️  需要重点关注的复杂函数 (可能需要重构):")
            for i, (func, path) in enumerate(most_complex_overall):
                rel_path = os.path.relpath(path, self.root_dir)
                print(f"   {i+1}. {func.name} (复杂度:{func.cognitive_complexity}) - {rel_path}")


def main():
    analyzer = GoComplexityAnalyzer()
    stats = analyzer.analyze_project()
    analyzer.print_analysis(stats)


if __name__ == "__main__":
    main() 